import os.path
from sys import stdout

from rich.status import Status

from .mlflow import sync_mlflow
from .tensorboard import sync_tensorboardX, sync_tensorboard_torch
from .wandb import sync_wandb

__all__ = ["sync_wandb", "sync_tensorboardX", "sync_tensorboard_torch", "sync_mlflow", "sync"]

from ..core_python import get_client, uploader
from ..data.namer import generate_colors
from ..log import swanlog
from swanlab.data.backup import BackupHandler, DataStore
from swanlab.proto.v0 import ModelsParser


def sync(
    dir_path: str,
    workspace: str = None,
    project_name: str = None,
    raise_error: bool = True,
    login_required: bool = True,
):
    """
    Syncs backup files to the cloud. Before syncing, you must log in.
    :param dir_path: The directory path to sync.
    :param workspace: The workspace to sync the logs to. If not specified, it will use the default workspace.
    :param project_name: The project to sync the logs to. If not specified, it will use the default project.
    :param raise_error: Whether to raise an error if error occurs when syncing.
    :param login_required: Whether login is required before syncing, just for debugging.
    """
    # ç¬¬ä¸€éƒ¨åˆ†ï¼Œå¤„ç†å¤‡ä»½æ–‡ä»¶ï¼Œè¯»å–å¤‡ä»½ä¿¡æ¯åˆ°å†…å­˜ä¸­
    try:
        with Status("ğŸ› ï¸Parsing...", spinner="dots"):
            assert os.path.exists(dir_path), f"Directory {dir_path} does not exist."
            file_path = os.path.join(dir_path, BackupHandler.BACKUP_FILE)
            assert os.path.exists(file_path), f"Can not find backup file {BackupHandler.BACKUP_FILE} in {dir_path}."
            try:
                client = get_client()
            except ValueError:
                client = None
                assert not login_required, "Please log in first, use `swanlab login` to log in."
            stdout.flush()
            ds = DataStore()
            ds.open_for_scan(file_path)
            # æ ¹æ®ç±»å‹åˆ†ç±»æ—¥å¿—æ–‡ä»¶
            with ModelsParser() as models_parser:
                for record in ds:
                    if record is None:
                        continue
                    models_parser.parse_record(record)
            header, project, experiment, logs, runtime, columns, scalars, medias, footer = models_parser.get_parsed()
            # 0. æ£€æŸ¥å¤‡ä»½æ–‡ä»¶
            assert (
                header.backup_type == "DEFAULT"
            ), f"Backup type mismatch: {header.backup_type}, please update your swanlab package."
            # 1. èšåˆä¿¡æ¯
            # 1.1 èšåˆæ—¥å¿—
            log_model_dict = {"INFO": [], "WARN": [], "ERROR": []}
            for log in logs:
                log_model = log.to_log_model()
                log_model_dict[log_model['level']].append(log_model)
            # 1.2 ç”Ÿæˆè¿è¡Œæ—¶
            runtime_model = runtime.to_file_model(os.path.join(dir_path, "files"))
            # 1.3 é›†åˆåˆ—
            column_models = [c.to_column_model() for c in columns]
            # 1.4 é›†åˆæŒ‡æ ‡
            scalar_models = [scalar.to_scalar_model() for scalar in scalars]
            # 1.5 é›†åˆåª’ä½“
            media_models = [media.to_media_model(os.path.join(dir_path, "media")) for media in medias]
            assert client is not None, "Please log in first, use `swanlab login` to log in."
    except Exception as e:
        if raise_error:
            raise e
        else:
            return swanlog.error(f"âŒ  Error parsing backup file: {e}")
    # ç¬¬äºŒéƒ¨åˆ†ï¼Œä¸Šä¼ æ•°æ®åˆ°äº‘ç«¯
    try:
        # 3. ä¸Šä¼ æ•°æ®
        # 3.1 åˆ›å»ºé¡¹ç›®ä¸å®éªŒ
        client.mount_project(
            name=project_name or project.name,
            username=workspace or project.workspace,
            public=project.public,
        )
        colors = generate_colors(client.history_exp_count)
        client.mount_exp(
            exp_name=experiment.name,
            colors=colors,
            description=experiment.description,
            tags=experiment.tags,
        )
        with Status("ğŸ” Syncing...", spinner="dots"):
            # 3.2 ä¸Šä¼ æ—¥å¿—
            for key in log_model_dict:
                if len(log_model_dict[key]) > 0:
                    uploader.upload_logs(log_model_dict[key])
            # 3.3 ä¸Šä¼ è¿è¡Œæ—¶
            uploader.upload_files([runtime_model])
            # 3.4 ä¸Šä¼ åˆ—ã€æ ‡é‡ã€åª’ä½“
            uploader.upload_columns(column_models)
            uploader.upload_scalar_metrics(scalar_models)
            uploader.upload_media_metrics(media_models)
            # 3.5 æ›´æ–°å®éªŒçŠ¶æ€
            client.update_state(success=footer.success if footer else False)
    except Exception as e:
        if raise_error:
            raise e
        else:
            swanlog.error(f"âŒ  Error uploading data: {e}")
            return
    swanlog.info("ğŸš€ Sync completed, View run at ", client.web_exp_url)
