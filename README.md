![Overview](readme_files/swanlab-overview-new.png)

<p align="center">
<a href="https://dev101.swanlab.cn">SwanLabåœ¨çº¿ç‰ˆ</a> Â· <a href="https://docs.dev101.swanlab.cn">æ–‡æ¡£</a> Â· <a href="https://geektechstudio.feishu.cn/wiki/NIZ9wp5LRiSqQykizbGcVzUKnic">å¾®ä¿¡</a> Â· <a href="https://github.com/swanhubx/swanlab/issues">æŠ¥å‘Šé—®é¢˜</a> Â· <a href="https://geektechstudio.feishu.cn/share/base/form/shrcnyBlK8OMD0eweoFcc2SvWKc">å»ºè®®åé¦ˆ</a>  Â· <a href="https://github.com/SwanHubX/SwanLab/blob/README-v0.3.0/CHANGELOG.md">æ›´æ–°æ—¥å¿—</a>
</p>

<p align="center">
  <a href="https://github.com/SwanHubX/SwanLab/blob/main/LICENSE"><img src="https://img.shields.io/github/license/SwanHubX/SwanLab.svg?color=brightgreen" alt="license"></a>
  <a href="https://github.com/SwanHubX/SwanLab/commits/main"><img src="https://img.shields.io/github/last-commit/SwanHubX/SwanLab" alt="license"></a>
  <a href="https://pypi.python.org/pypi/swanlab"><img src="https://img.shields.io/pypi/v/swanlab?color=orange" alt= /></a>
  <a href="https://pepy.tech/project/swanlab"><img alt="pypi Download" src="https://static.pepy.tech/badge/swanlab"></a>
  <a href="https://github.com/swanhubx/swanlab/issues"><img alt="issues" src="https://img.shields.io/github/issues/swanhubx/swanlab"></a> 
  <br>
  <a href="https://dev101.swanlab.cn" target="_blank">
        <img alt="Static Badge" src="https://img.shields.io/badge/Product-SwanLabäº‘ç«¯ç‰ˆ-636a3f"></a>
  <a href="https://geektechstudio.feishu.cn/wiki/NIZ9wp5LRiSqQykizbGcVzUKnic" target="_blank">
        <img alt="Static Badge" src="https://img.shields.io/badge/WeChat-å¾®ä¿¡-4cb55e"></a>
  <a href="https://www.xiaohongshu.com/user/profile/605786b90000000001003a81" target="_blank">
        <img alt="Static Badge" src="https://img.shields.io/badge/å°çº¢ä¹¦-F04438"></a>

</p>

<div align="center">
  <a href="README_en.md"><img alt="è‹±æ–‡æ–‡æ¡£" src="https://img.shields.io/badge/English-d9d9d9"></a>
  <a href="README.md"><img alt="ä¸­æ–‡æ–‡æ¡£" src="https://img.shields.io/badge/ç®€ä½“ä¸­æ–‡-d9d9d9"></a>
</div>

<details>
<summary>ç›®å½•æ ‘</summary>

#### TOC

- [ğŸ‘‹ğŸ» ä»€ä¹ˆæ˜¯SwanLab](#-ä»€ä¹ˆæ˜¯swanlab)
- [ğŸ å¿«é€Ÿå¼€å§‹](#-å¿«é€Ÿå¼€å§‹)
    - [1.å®‰è£…](#1å®‰è£…)
    - [2.ç™»å½•å¹¶è·å–API Key](#2ç™»å½•å¹¶è·å–api-key)
    - [3.å°†SwanLabä¸ä½ çš„ä»£ç é›†æˆ](#3å°†SwanLabä¸ä½ çš„ä»£ç é›†æˆ)
- [ğŸ“ƒ æ›´å¤šæ¡ˆä¾‹](#-æ›´å¤šæ¡ˆä¾‹)
- [ğŸ’» è‡ªæ‰˜ç®¡](#-è‡ªæ‰˜ç®¡)
    - [ç¦»çº¿å®éªŒè·Ÿè¸ª](#ç¦»çº¿å®éªŒè·Ÿè¸ª)
    - [å¼€å¯ç¦»çº¿çœ‹æ¿](#å¼€å¯ç¦»çº¿çœ‹æ¿)
- [ğŸš— æ¡†æ¶é›†æˆ](#-æ¡†æ¶é›†æˆ)
- [ğŸ†š ä¸ç†Ÿæ‚‰çš„å·¥å…·çš„æ¯”è¾ƒ](#-ä¸ç†Ÿæ‚‰çš„å·¥å…·çš„æ¯”è¾ƒ)
    - [Tensorboard vs SwanLab](#tensorboard-vs-swanlab)
    - [W&B vs SwanLab](#weights-and-biases-vs-swanlab)
- [ğŸ›£ï¸ Roadmap](#%EF%B8%8F-roadmap)
    - [ä¸¤å‘¨å†…å³å°†ä¸Šçº¿](#ä¸¤å‘¨å†…å³å°†ä¸Šçº¿)
    - [ä¸‰ä¸ªæœˆå†…è§„åˆ’ä¸Šçº¿](#ä¸‰ä¸ªæœˆå†…è§„åˆ’ä¸Šçº¿)
    - [é•¿æœŸå…³æ³¨](#é•¿æœŸå…³æ³¨)
- [ğŸ‘¥ ç¤¾åŒº](#-ç¤¾åŒº)
    - [ç¤¾åŒºä¸æ”¯æŒ](#ç¤¾åŒºä¸æ”¯æŒ)
    - [SwanLab READMEå¾½ç« ](#swanlab-readmeå¾½ç« )
    - [åœ¨è®ºæ–‡ä¸­å¼•ç”¨SwanLab](#åœ¨è®ºæ–‡ä¸­å¼•ç”¨swanlab)
    - [ä¸ºSwanLabåšå‡ºè´¡çŒ®](#ä¸ºswanlabåšå‡ºè´¡çŒ®)
    - [ä¸‹è½½Icon](#ä¸‹è½½icon)
- [ğŸ“ƒ åè®®](#-åè®®)

<br/>

</details>

## ğŸ‘‹ğŸ» ä»€ä¹ˆæ˜¯SwanLab

SwanLab is an open-source, lightweight AI experiment tracking tool that provides a platform for tracking, comparing, and
collaborating on experiments, aiming to accelerate the research and development efficiency of AI teams by 100 times.

SwanLabæ˜¯ä¸€æ¬¾å¼€æºã€è½»é‡çº§çš„AIå®éªŒè·Ÿè¸ªå·¥å…·ï¼Œæä¾›äº†ä¸€ä¸ªè·Ÿè¸ªã€æ¯”è¾ƒã€å’Œåä½œå®éªŒçš„å¹³å°ï¼Œæ—¨åœ¨åŠ é€ŸAIç ”å‘å›¢é˜Ÿ100å€çš„ç ”å‘æ•ˆç‡ã€‚

å…¶æä¾›äº†å‹å¥½çš„APIå’Œæ¼‚äº®çš„ç•Œé¢ï¼Œç»“åˆäº†è¶…å‚æ•°è·Ÿè¸ªã€æŒ‡æ ‡è®°å½•ã€åœ¨çº¿åä½œã€å®éªŒé“¾æ¥åˆ†äº«ã€å®æ—¶æ¶ˆæ¯é€šçŸ¥ç­‰åŠŸèƒ½ï¼Œè®©æ‚¨å¯ä»¥å¿«é€Ÿè·Ÿè¸ªMLå®éªŒã€å¯è§†åŒ–è¿‡ç¨‹ã€åˆ†äº«ç»™åŒä¼´ã€‚

å€ŸåŠ©SwanLabï¼Œç§‘ç ”äººå‘˜å¯ä»¥æ²‰æ·€è‡ªå·±çš„æ¯ä¸€æ¬¡è®­ç»ƒç»éªŒï¼Œä¸åˆä½œè€…æ— ç¼åœ°äº¤æµå’Œåä½œï¼Œæœºå™¨å­¦ä¹ å·¥ç¨‹å¸ˆå¯ä»¥æ›´å¿«åœ°å¼€å‘å¯ç”¨äºç”Ÿäº§çš„æ¨¡å‹ã€‚

![](readme_files/introduction.png)

ä»¥ä¸‹æ˜¯å…¶æ ¸å¿ƒç‰¹æ€§åˆ—è¡¨ï¼š

**1. ğŸ“Šå®éªŒæŒ‡æ ‡ä¸è¶…å‚æ•°è·Ÿè¸ª**: æç®€çš„ä»£ç åµŒå…¥æ‚¨çš„æœºå™¨å­¦ä¹ pipelineï¼Œè·Ÿè¸ªè®°å½•è®­ç»ƒå…³é”®æŒ‡æ ‡

- è‡ªç”±çš„è¶…å‚æ•°ä¸å®éªŒé…ç½®è®°å½•
- æ”¯æŒçš„å…ƒæ•°æ®ç±»å‹ï¼šæ ‡é‡æŒ‡æ ‡ã€å›¾åƒã€éŸ³é¢‘ã€æ–‡æœ¬ã€...
- æ”¯æŒçš„å›¾è¡¨ç±»å‹ï¼šæŠ˜çº¿å›¾ã€åª’ä½“å›¾ï¼ˆå›¾åƒã€éŸ³é¢‘ã€æ–‡æœ¬ï¼‰ã€...
- è‡ªåŠ¨è®°å½•ï¼šæ§åˆ¶å°loggingã€GPUç¡¬ä»¶ã€Gitä¿¡æ¯ã€Pythonè§£é‡Šå™¨ã€Pythonåº“åˆ—è¡¨ã€ä»£ç ç›®å½•

**2. âš¡ï¸å…¨é¢çš„æ¡†æ¶é›†æˆ**: PyTorchã€Tensorflowã€PyTorch Lightningã€ğŸ¤—HuggingFace
Transformersã€MMEngineã€OpenAIã€ZhipuAIã€Hydraã€...

**3. ğŸ“¦ç»„ç»‡å®éªŒ**: é›†ä¸­å¼ä»ªè¡¨æ¿ï¼Œå¿«é€Ÿç®¡ç†å¤šä¸ªé¡¹ç›®ä¸å®éªŒï¼Œé€šè¿‡æ•´ä½“è§†å›¾é€Ÿè§ˆè®­ç»ƒå…¨å±€

**4. ğŸ†šæ¯”è¾ƒç»“æœ**: é€šè¿‡åœ¨çº¿è¡¨æ ¼ä¸å¯¹æ¯”å›¾è¡¨æ¯”è¾ƒä¸åŒå®éªŒçš„è¶…å‚æ•°å’Œç»“æœï¼ŒæŒ–æ˜è¿­ä»£çµæ„Ÿ

**5. ğŸ‘¥åœ¨çº¿åä½œ**: æ‚¨å¯ä»¥ä¸å›¢é˜Ÿè¿›è¡Œåä½œå¼è®­ç»ƒï¼Œæ”¯æŒå°†å®éªŒå®æ—¶åŒæ­¥åœ¨ä¸€ä¸ªé¡¹ç›®ä¸‹ï¼Œæ‚¨å¯ä»¥åœ¨çº¿æŸ¥çœ‹å›¢é˜Ÿçš„è®­ç»ƒè®°å½•ï¼ŒåŸºäºç»“æœå‘è¡¨çœ‹æ³•ä¸å»ºè®®

**6. âœ‰ï¸åˆ†äº«ç»“æœ**: å¤åˆ¶å’Œå‘é€æŒä¹…çš„URLæ¥å…±äº«æ¯ä¸ªå®éªŒï¼Œæ–¹ä¾¿åœ°å‘é€ç»™ä¼™ä¼´ï¼Œæˆ–åµŒå…¥åˆ°åœ¨çº¿ç¬”è®°ä¸­

**7. ğŸ’»æ”¯æŒè‡ªæ‰˜ç®¡**: æ”¯æŒä¸è”ç½‘ä½¿ç”¨ï¼Œè‡ªæ‰˜ç®¡çš„ç¤¾åŒºç‰ˆåŒæ ·å¯ä»¥æŸ¥çœ‹ä»ªè¡¨ç›˜ä¸ç®¡ç†å®éªŒ

> \[!IMPORTANT]
>
> **æ”¶è—é¡¹ç›®**ï¼Œä½ å°†ä» GitHub ä¸Šæ— å»¶è¿Ÿåœ°æ¥æ”¶æ‰€æœ‰å‘å¸ƒé€šçŸ¥ï½â­ï¸

![star-us](readme_files/star-us.png)

<br>

## ğŸ å¿«é€Ÿå¼€å§‹

### 1.å®‰è£…

```bash
pip install swanlab
```

### 2.ç™»å½•å¹¶è·å–API Key

1. å…è´¹[æ³¨å†Œè´¦å·](https://dev101.swanlab.cn)

2. ç™»å½•è´¦å·ï¼Œåœ¨ç”¨æˆ·è®¾ç½® > [API Key](https://dev101.swanlab.cn/settings) é‡Œå¤åˆ¶æ‚¨çš„API Key

3. æ‰“å¼€ç»ˆç«¯ï¼Œè¾“å…¥ï¼š

```bash
swanlab login
```

å‡ºç°æç¤ºæ—¶ï¼Œè¾“å…¥æ‚¨çš„API Keyï¼ŒæŒ‰ä¸‹å›è½¦ï¼Œå®Œæˆç™»é™†ã€‚

### 3.å°†SwanLabä¸ä½ çš„ä»£ç é›†æˆ

```python
import swanlab

# åˆå§‹åŒ–ä¸€ä¸ªæ–°çš„swanlabå®éªŒ
swanlab.init(
    project="my-first-ml",
    config={'learning-rate': 0.003}
)

# è®°å½•æŒ‡æ ‡
for i in range(10):
    swanlab.log({"loss": i})
```

å¤§åŠŸå‘Šæˆï¼å‰å¾€[SwanLab](https://dev101.swanlab.cn)æŸ¥çœ‹ä½ çš„ç¬¬ä¸€ä¸ªSwanLabå®éªŒã€‚

![MNIST](readme_files/readme-mnist.png)

<br>

## ğŸ“ƒ æ›´å¤šæ¡ˆä¾‹

<details>
<summary>MNIST</summary>

```python
import os
import torch
from torch import nn, optim, utils
import torch.nn.functional as F
from torchvision.datasets import MNIST
from torchvision.transforms import ToTensor
import swanlab


# CNNç½‘ç»œæ„å»º
class ConvNet(nn.Module):
    def __init__(self):
        super().__init__()
        # 1,28x28
        self.conv1 = nn.Conv2d(1, 10, 5)  # 10, 24x24
        self.conv2 = nn.Conv2d(10, 20, 3)  # 128, 10x10
        self.fc1 = nn.Linear(20 * 10 * 10, 500)
        self.fc2 = nn.Linear(500, 10)

    def forward(self, x):
        in_size = x.size(0)
        out = self.conv1(x)  # 24
        out = F.relu(out)
        out = F.max_pool2d(out, 2, 2)  # 12
        out = self.conv2(out)  # 10
        out = F.relu(out)
        out = out.view(in_size, -1)
        out = self.fc1(out)
        out = F.relu(out)
        out = self.fc2(out)
        out = F.log_softmax(out, dim=1)
        return out


# æ•è·å¹¶å¯è§†åŒ–å‰20å¼ å›¾åƒ
def log_images(loader, num_images=16):
    images_logged = 0
    logged_images = []
    for images, labels in loader:
        # images: batch of images, labels: batch of labels
        for i in range(images.shape[0]):
            if images_logged < num_images:
                # ä½¿ç”¨swanlab.Imageå°†å›¾åƒè½¬æ¢ä¸ºwandbå¯è§†åŒ–æ ¼å¼
                logged_images.append(swanlab.Image(images[i], caption=f"Label: {labels[i]}"))
                images_logged += 1
            else:
                break
        if images_logged >= num_images:
            break
    swanlab.log({"MNIST-Preview": logged_images})


if __name__ == "__main__":

    # åˆå§‹åŒ–swanlab
    run = swanlab.init(
        project="MNIST-example",
        experiment_name="ConvNet",
        description="Train ConvNet on MNIST dataset.",
        config={
            "model": "CNN",
            "optim": "Adam",
            "lr": 0.001,
            "batch_size": 512,
            "num_epochs": 10,
            "train_dataset_num": 55000,
            "val_dataset_num": 5000,
        },
    )

    # è®¾ç½®è®­ç»ƒæœºã€éªŒè¯é›†å’Œæµ‹è¯•é›†
    dataset = MNIST(os.getcwd(), train=True, download=True, transform=ToTensor())
    train_dataset, val_dataset = utils.data.random_split(
        dataset, [run.config.train_dataset_num, run.config.val_dataset_num]
    )

    train_loader = utils.data.DataLoader(train_dataset, batch_size=run.config.batch_size, shuffle=True)
    val_loader = utils.data.DataLoader(val_dataset, batch_size=1, shuffle=False)

    # åˆå§‹åŒ–æ¨¡å‹ã€æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
    model = ConvNet()
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=run.config.lr)

    # ï¼ˆå¯é€‰ï¼‰çœ‹ä¸€ä¸‹æ•°æ®é›†çš„å‰16å¼ å›¾åƒ
    log_images(train_loader, 16)

    # å¼€å§‹è®­ç»ƒ
    for epoch in range(1, run.config.num_epochs):
        swanlab.log({"train/epoch": epoch})
        # è®­ç»ƒå¾ªç¯
        for iter, batch in enumerate(train_loader):
            x, y = batch
            optimizer.zero_grad()
            output = model(x)
            loss = criterion(output, y)
            loss.backward()
            optimizer.step()

            print(
                f"Epoch [{epoch}/{run.config.num_epochs}], Iteration [{iter + 1}/{len(train_loader)}], Loss: {loss.item()}"
            )

            if iter % 20 == 0:
                swanlab.log({"train/loss": loss.item()}, step=(epoch - 1) * len(train_loader) + iter)

        # æ¯4ä¸ªepochéªŒè¯ä¸€æ¬¡
        if epoch % 2 == 0:
            model.eval()
            correct = 0
            total = 0
            with torch.no_grad():
                for batch in val_loader:
                    x, y = batch
                    output = model(x)
                    _, predicted = torch.max(output, 1)
                    total += y.size(0)
                    correct += (predicted == y).sum().item()

            accuracy = correct / total
            swanlab.log({"val/accuracy": accuracy})

```

</details>

<details>
<summary>FashionMNSIT-ResNet34</summary>

```python
import os
import torch
from torch import nn, optim, utils
import torch.nn.functional as F
from torchvision.datasets import FashionMNIST
from torchvision.transforms import ToTensor
import swanlab


# ResNetç½‘ç»œæ„å»º
class Basicblock(nn.Module):
    def __init__(self, in_planes, planes, stride=1):
        super(Basicblock, self).__init__()
        self.conv1 = nn.Sequential(
            nn.Conv2d(in_channels=in_planes, out_channels=planes, kernel_size=3, stride=stride, padding=1, bias=False),
            nn.BatchNorm2d(planes),
            nn.ReLU()
        )
        self.conv2 = nn.Sequential(
            nn.Conv2d(in_channels=planes, out_channels=planes, kernel_size=3, stride=1, padding=1, bias=False),
            nn.BatchNorm2d(planes),
        )

        if stride != 1 or in_planes != planes:
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_channels=in_planes, out_channels=planes, kernel_size=3, stride=stride, padding=1),
                nn.BatchNorm2d(planes)
            )
        else:
            self.shortcut = nn.Sequential()

    def forward(self, x):
        out = self.conv1(x)
        out = self.conv2(out)
        out += self.shortcut(x)
        out = F.relu(out)
        return out


class ResNet(nn.Module):
    def __init__(self, block, num_block, num_classes):
        super(ResNet, self).__init__()
        self.in_planes = 16
        self.conv1 = nn.Sequential(
            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(16),
            nn.ReLU()
        )
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)

        self.block1 = self._make_layer(block, 16, num_block[0], stride=1)
        self.block2 = self._make_layer(block, 32, num_block[1], stride=2)
        self.block3 = self._make_layer(block, 64, num_block[2], stride=2)
        # self.block4 = self._make_layer(block, 512, num_block[3], stride=2)

        self.outlayer = nn.Linear(64, num_classes)

    def _make_layer(self, block, planes, num_block, stride):
        layers = []
        for i in range(num_block):
            if i == 0:
                layers.append(block(self.in_planes, planes, stride))
            else:
                layers.append(block(planes, planes, 1))
        self.in_planes = planes
        return nn.Sequential(*layers)

    def forward(self, x):
        x = self.maxpool(self.conv1(x))
        x = self.block1(x)  # [200, 64, 28, 28]
        x = self.block2(x)  # [200, 128, 14, 14]
        x = self.block3(x)  # [200, 256, 7, 7]
        # out = self.block4(out)
        x = F.avg_pool2d(x, 7)  # [200, 256, 1, 1]
        x = x.view(x.size(0), -1)  # [200,256]
        out = self.outlayer(x)
        return out


# æ•è·å¹¶å¯è§†åŒ–å‰20å¼ å›¾åƒ
def log_images(loader, num_images=16):
    images_logged = 0
    logged_images = []
    for images, labels in loader:
        # images: batch of images, labels: batch of labels
        for i in range(images.shape[0]):
            if images_logged < num_images:
                # ä½¿ç”¨swanlab.Imageå°†å›¾åƒè½¬æ¢ä¸ºwandbå¯è§†åŒ–æ ¼å¼
                logged_images.append(swanlab.Image(images[i], caption=f"Label: {labels[i]}", size=(128, 128)))
                images_logged += 1
            else:
                break
        if images_logged >= num_images:
            break
    swanlab.log({"Preview/MNIST": logged_images})


if __name__ == "__main__":
    # è®¾ç½®device
    try:
        use_mps = torch.backends.mps.is_available()
    except AttributeError:
        use_mps = False

    if torch.cuda.is_available():
        device = "cuda"
    elif use_mps:
        device = "mps"
    else:
        device = "cpu"

    # åˆå§‹åŒ–swanlab
    run = swanlab.init(
        project="FashionMNIST",
        workspace="SwanLab",
        experiment_name="Resnet18-Adam",
        config={
            "model": "Resnet34",
            "optim": "Adam",
            "lr": 0.001,
            "batch_size": 32,
            "num_epochs": 10,
            "train_dataset_num": 55000,
            "val_dataset_num": 5000,
            "device": device,
            "num_classes": 10,
        },
    )

    # è®¾ç½®è®­ç»ƒæœºã€éªŒè¯é›†å’Œæµ‹è¯•é›†
    dataset = FashionMNIST(os.getcwd(), train=True, download=True, transform=ToTensor())
    train_dataset, val_dataset = utils.data.random_split(
        dataset, [run.config.train_dataset_num, run.config.val_dataset_num]
    )

    train_loader = utils.data.DataLoader(train_dataset, batch_size=run.config.batch_size, shuffle=True)
    val_loader = utils.data.DataLoader(val_dataset, batch_size=1, shuffle=False)

    # åˆå§‹åŒ–æ¨¡å‹ã€æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
    if run.config.model == "Resnet18":
        model = ResNet(Basicblock, [1, 1, 1, 1], 10)
    elif run.config.model == "Resnet34":
        model = ResNet(Basicblock, [2, 3, 5, 2], 10)
    elif run.config.model == "Resnet50":
        model = ResNet(Basicblock, [3, 4, 6, 3], 10)

    model.to(torch.device(device))

    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=run.config.lr)

    # ï¼ˆå¯é€‰ï¼‰çœ‹ä¸€ä¸‹æ•°æ®é›†çš„å‰16å¼ å›¾åƒ
    log_images(train_loader, 16)

    # å¼€å§‹è®­ç»ƒ
    for epoch in range(1, run.config.num_epochs + 1):
        swanlab.log({"train/epoch": epoch}, step=epoch)
        # è®­ç»ƒå¾ªç¯
        for iter, batch in enumerate(train_loader):
            x, y = batch
            x, y = x.to(device), y.to(device)
            optimizer.zero_grad()
            output = model(x)
            loss = criterion(output, y)
            loss.backward()
            optimizer.step()

            if iter % 40 == 0:
                print(
                    f"Epoch [{epoch}/{run.config.num_epochs}], Iteration [{iter + 1}/{len(train_loader)}], Loss: {loss.item()}"
                )
                swanlab.log({"train/loss": loss.item()}, step=(epoch - 1) * len(train_loader) + iter)

        # æ¯4ä¸ªepochéªŒè¯ä¸€æ¬¡
        if epoch % 2 == 0:
            model.eval()
            correct = 0
            total = 0
            with torch.no_grad():
                for batch in val_loader:
                    x, y = batch
                    x, y = x.to(device), y.to(device)
                    output = model(x)
                    _, predicted = torch.max(output, 1)
                    total += y.size(0)
                    correct += (predicted == y).sum().item()

            accuracy = correct / total
            swanlab.log({"val/accuracy": accuracy}, step=epoch)
```

</details>


<br>

## ğŸ’» è‡ªæ‰˜ç®¡

è‡ªæ‰˜ç®¡ç¤¾åŒºç‰ˆæ”¯æŒç¦»çº¿æŸ¥çœ‹SwanLabä»ªè¡¨ç›˜ã€‚

### ç¦»çº¿å®éªŒè·Ÿè¸ª

åœ¨swanlab.initä¸­è®¾ç½®`logir`å’Œ`cloud`è¿™ä¸¤ä¸ªå‚æ•°ï¼Œå³å¯ç¦»çº¿è·Ÿè¸ªå®éªŒï¼š

```python
...

swanlab.init(
    logdir='./logs',
    cloud=False,
)

...
```

- å‚æ•°`cloud`è®¾ç½®ä¸º`False`ï¼Œå…³é—­å°†å®éªŒåŒæ­¥åˆ°äº‘ç«¯

- å‚æ•°`logdir`çš„è®¾ç½®æ˜¯å¯é€‰çš„ï¼Œå®ƒçš„ä½œç”¨æ˜¯æŒ‡å®šäº†SwanLabæ—¥å¿—æ–‡ä»¶çš„ä¿å­˜ä½ç½®ï¼ˆé»˜è®¤ä¿å­˜åœ¨`swanlog`æ–‡ä»¶å¤¹ä¸‹ï¼‰

    - æ—¥å¿—æ–‡ä»¶ä¼šåœ¨è·Ÿè¸ªå®éªŒçš„è¿‡ç¨‹ä¸­è¢«åˆ›å»ºå’Œæ›´æ–°ï¼Œç¦»çº¿çœ‹æ¿çš„å¯åŠ¨ä¹Ÿå°†åŸºäºè¿™äº›æ—¥å¿—æ–‡ä»¶

å…¶ä»–éƒ¨åˆ†å’Œäº‘ç«¯ä½¿ç”¨å®Œå…¨ä¸€è‡´ã€‚

### å¼€å¯ç¦»çº¿çœ‹æ¿

æ‰“å¼€ç»ˆç«¯ï¼Œä½¿ç”¨ä¸‹é¢çš„æŒ‡ä»¤ï¼Œå¼€å¯ä¸€ä¸ªSwanLabä»ªè¡¨æ¿:

```bash
swanlab watch -l ./logs
```

è¿è¡Œå®Œæˆåï¼ŒSwanLabä¼šç»™ä½ 1ä¸ªæœ¬åœ°çš„URLé“¾æ¥ï¼ˆé»˜è®¤æ˜¯[http://127.0.0.1:5092](http://127.0.0.1:5092)ï¼‰

è®¿é—®è¯¥é“¾æ¥ï¼Œå°±å¯ä»¥åœ¨æµè§ˆå™¨ç”¨ç¦»çº¿çœ‹æ¿æŸ¥çœ‹å®éªŒäº†ã€‚

<br>

## ğŸš— æ¡†æ¶é›†æˆ

å°†æ‚¨æœ€å–œæ¬¢çš„æ¡†æ¶ä¸SwanLabç»“åˆä½¿ç”¨ï¼Œ[æ›´å¤šé›†æˆ](https://docs.dev101.swanlab.cn/zh/guide_cloud/integration/integration-pytorch-lightning.html)ã€‚

<details>
  <summary>
    <strong>âš¡ï¸ PyTorch Lightning</strong>
  </summary>
  <br>

ä½¿ç”¨`SwanLabLogger`åˆ›å»ºç¤ºä¾‹ï¼Œå¹¶ä»£å…¥`Trainer`çš„`logger`å‚æ•°ä¸­ï¼Œå³å¯å®ç°SwanLabè®°å½•è®­ç»ƒæŒ‡æ ‡ã€‚

```python
from swanlab.integration.pytorch_lightning import SwanLabLogger
import importlib.util
import os
import pytorch_lightning as pl
from torch import nn, optim, utils
from torchvision.datasets import MNIST
from torchvision.transforms import ToTensor

encoder = nn.Sequential(nn.Linear(28 * 28, 128), nn.ReLU(), nn.Linear(128, 3))
decoder = nn.Sequential(nn.Linear(3, 128), nn.ReLU(), nn.Linear(128, 28 * 28))


class LitAutoEncoder(pl.LightningModule):
    def __init__(self, encoder, decoder):
        super().__init__()
        self.encoder = encoder
        self.decoder = decoder

    def training_step(self, batch, batch_idx):
        # training_step defines the train loop.
        # it is independent of forward
        x, y = batch
        x = x.view(x.size(0), -1)
        z = self.encoder(x)
        x_hat = self.decoder(z)
        loss = nn.functional.mse_loss(x_hat, x)
        # Logging to TensorBoard (if installed) by default
        self.log("train_loss", loss)
        return loss

    def test_step(self, batch, batch_idx):
        # test_step defines the test loop.
        # it is independent of forward
        x, y = batch
        x = x.view(x.size(0), -1)
        z = self.encoder(x)
        x_hat = self.decoder(z)
        loss = nn.functional.mse_loss(x_hat, x)
        # Logging to TensorBoard (if installed) by default
        self.log("test_loss", loss)
        return loss

    def configure_optimizers(self):
        optimizer = optim.Adam(self.parameters(), lr=1e-3)
        return optimizer


# init the autoencoder
autoencoder = LitAutoEncoder(encoder, decoder)

# setup data
dataset = MNIST(os.getcwd(), train=True, download=True, transform=ToTensor())
train_dataset, val_dataset = utils.data.random_split(dataset, [55000, 5000])
test_dataset = MNIST(os.getcwd(), train=False, download=True, transform=ToTensor())

train_loader = utils.data.DataLoader(train_dataset)
val_loader = utils.data.DataLoader(val_dataset)
test_loader = utils.data.DataLoader(test_dataset)

swanlab_logger = SwanLabLogger(
    project="swanlab_example",
    experiment_name="example_experiment",
    cloud=False,
)

trainer = pl.Trainer(limit_train_batches=100, max_epochs=5, logger=swanlab_logger)

trainer.fit(model=autoencoder, train_dataloaders=train_loader, val_dataloaders=val_loader)
trainer.test(dataloaders=test_loader)

```

</details>

<details>
<summary>
  <strong> ğŸ¤—HuggingFace Transformers</strong>
</summary>

<br>

ä½¿ç”¨`SwanLabCallback`åˆ›å»ºç¤ºä¾‹ï¼Œå¹¶ä»£å…¥`Trainer`çš„`callbacks`å‚æ•°ä¸­ï¼Œå³å¯å®ç°SwanLabè®°å½•è®­ç»ƒæŒ‡æ ‡ã€‚

```python
import evaluate
import numpy as np
import swanlab
from swanlab.integration.huggingface import SwanLabCallback
from datasets import load_dataset
from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments


def tokenize_function(examples):
    return tokenizer(examples["text"], padding="max_length", truncation=True)


def compute_metrics(eval_pred):
    logits, labels = eval_pred
    predictions = np.argmax(logits, axis=-1)
    return metric.compute(predictions=predictions, references=labels)


dataset = load_dataset("yelp_review_full")

tokenizer = AutoTokenizer.from_pretrained("bert-base-cased")

tokenized_datasets = dataset.map(tokenize_function, batched=True)

small_train_dataset = tokenized_datasets["train"].shuffle(seed=42).select(range(1000))
small_eval_dataset = tokenized_datasets["test"].shuffle(seed=42).select(range(1000))

metric = evaluate.load("accuracy")

model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", num_labels=5)

training_args = TrainingArguments(
    output_dir="test_trainer",
    report_to="none",
    num_train_epochs=3,
    logging_steps=50,
)

swanlab_callback = SwanLabCallback(experiment_name="TransformersTest", cloud=False)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=small_train_dataset,
    eval_dataset=small_eval_dataset,
    compute_metrics=compute_metrics,
    callbacks=[swanlab_callback],
)

trainer.train()
```

</details>

<br>

## ğŸ†š ä¸ç†Ÿæ‚‰çš„å·¥å…·çš„æ¯”è¾ƒ

### Tensorboard vs SwanLab

- **â˜ï¸æ”¯æŒåœ¨çº¿ä½¿ç”¨**ï¼š
  é€šè¿‡SwanLabå¯ä»¥æ–¹ä¾¿åœ°å°†è®­ç»ƒå®éªŒåœ¨äº‘ç«¯åœ¨çº¿åŒæ­¥ä¸ä¿å­˜ï¼Œä¾¿äºè¿œç¨‹æŸ¥çœ‹è®­ç»ƒè¿›å±•ã€ç®¡ç†å†å²é¡¹ç›®ã€åˆ†äº«å®éªŒé“¾æ¥ã€å‘é€å®æ—¶æ¶ˆæ¯é€šçŸ¥ã€å¤šç«¯çœ‹å®éªŒç­‰ã€‚è€ŒTensorboardæ˜¯ä¸€ä¸ªç¦»çº¿çš„å®éªŒè·Ÿè¸ªå·¥å…·ã€‚

- **ğŸ‘¥å¤šäººåä½œ**ï¼š
  åœ¨è¿›è¡Œå¤šäººã€è·¨å›¢é˜Ÿçš„æœºå™¨å­¦ä¹ åä½œæ—¶ï¼Œé€šè¿‡SwanLabå¯ä»¥è½»æ¾ç®¡ç†å¤šäººçš„è®­ç»ƒé¡¹ç›®ã€åˆ†äº«å®éªŒé“¾æ¥ã€è·¨ç©ºé—´äº¤æµè®¨è®ºã€‚è€ŒTensorboardä¸»è¦ä¸ºä¸ªäººè®¾è®¡ï¼Œéš¾ä»¥è¿›è¡Œå¤šäººåä½œå’Œåˆ†äº«å®éªŒã€‚

- **ğŸ’»æŒä¹…ã€é›†ä¸­çš„ä»ªè¡¨æ¿**ï¼š
  æ— è®ºä½ åœ¨ä½•å¤„è®­ç»ƒæ¨¡å‹ï¼Œæ— è®ºæ˜¯åœ¨æœ¬åœ°è®¡ç®—æœºä¸Šã€åœ¨å®éªŒå®¤é›†ç¾¤è¿˜æ˜¯åœ¨å…¬æœ‰äº‘çš„GPUå®ä¾‹ä¸­ï¼Œä½ çš„ç»“æœéƒ½ä¼šè®°å½•åˆ°åŒä¸€ä¸ªé›†ä¸­å¼ä»ªè¡¨æ¿ä¸­ã€‚è€Œä½¿ç”¨TensorBoardéœ€è¦èŠ±è´¹æ—¶é—´ä»ä¸åŒçš„æœºå™¨å¤åˆ¶å’Œç®¡ç†
  TFEventæ–‡ä»¶ã€‚

- **ğŸ’ªæ›´å¼ºå¤§çš„è¡¨æ ¼**ï¼š
  é€šè¿‡SwanLabè¡¨æ ¼å¯ä»¥æŸ¥çœ‹ã€æœç´¢ã€è¿‡æ»¤æ¥è‡ªä¸åŒå®éªŒçš„ç»“æœï¼Œå¯ä»¥è½»æ¾æŸ¥çœ‹æ•°åƒä¸ªæ¨¡å‹ç‰ˆæœ¬å¹¶æ‰¾åˆ°é€‚åˆä¸åŒä»»åŠ¡çš„æœ€ä½³æ€§èƒ½æ¨¡å‹ã€‚
  TensorBoard ä¸é€‚ç”¨äºå¤§å‹é¡¹ç›®ã€‚

### Weights and Biases vs SwanLab

- Weights and Biases æ˜¯ä¸€ä¸ªå¿…é¡»è”ç½‘ä½¿ç”¨çš„é—­æºMLOpså¹³å°

- SwanLab ä¸ä»…æ”¯æŒè”ç½‘ä½¿ç”¨ï¼Œä¹Ÿæ”¯æŒå¼€æºã€å…è´¹ã€è‡ªæ‰˜ç®¡çš„ç‰ˆæœ¬

<br>

## ğŸ›£ï¸ Roadmap

å·¥å…·åœ¨è¿­ä»£ä¸åé¦ˆä¸­è¿›åŒ–ï½ï¼Œæ¬¢è¿[æäº¤åŠŸèƒ½å»ºè®®](https://geektechstudio.feishu.cn/share/base/form/shrcnyBlK8OMD0eweoFcc2SvWKc)

### ä¸¤å‘¨å†…å³å°†ä¸Šçº¿

- `Table`: æ›´çµæ´»çš„å¤šç»´è¡¨æ ¼å›¾è¡¨ï¼Œé€‚ç”¨äºLLMã€AIGCã€æ¨¡å‹è¯„ä¼°ç­‰åœºæ™¯
- **é‚®ä»¶é€šçŸ¥ğŸ“§**: è®­ç»ƒæ„å¤–ä¸­æ–­ã€è®­ç»ƒå®Œæˆã€è‡ªå®šä¹‰æƒ…å†µç­‰åœºæ™¯è§¦è¾¾æ—¶ï¼Œå‘é€é€šçŸ¥é‚®ä»¶

### ä¸‰ä¸ªæœˆå†…è§„åˆ’ä¸Šçº¿

- `Molecule`: ç”Ÿç‰©åŒ–å­¦åˆ†å­å¯è§†åŒ–å›¾è¡¨
- `Plot`: è‡ªç”±çš„å›¾è¡¨ç»˜åˆ¶æ–¹å¼
- `Api`: é€šè¿‡APIè®¿é—®SwanLabæ•°æ®
- **ç³»ç»Ÿç¡¬ä»¶è®°å½•**: è®°å½•GPUã€CPUã€ç£ç›˜ã€ç½‘ç»œç­‰ä¸€ç³»åˆ—ç¡¬ä»¶æƒ…å†µ
- **ä»£ç è®°å½•**: è®°å½•è®­ç»ƒä»£ç 
- **æ›´å¤šé›†æˆ**: LightGBMã€XGBoostã€openaiã€chatglmã€mmç³»åˆ—ã€...ï¼‰
- ...

### é•¿æœŸå…³æ³¨

- æœ€æœ‰åˆ©äºAIå›¢é˜Ÿåˆ›æ–°çš„ååŒæ–¹å¼
- æœ€å‹å¥½çš„UIäº¤äº’
- ç§»åŠ¨ç«¯çœ‹å®éªŒ

<br>

## ğŸ‘¥ ç¤¾åŒº

### ç¤¾åŒºä¸æ”¯æŒ

- [GitHub Issues](https://github.com/SwanHubX/SwanLab/issues)ï¼šä½¿ç”¨SwanLabæ—¶é‡åˆ°çš„é”™è¯¯å’Œé—®é¢˜
- [ç”µå­é‚®ä»¶æ”¯æŒ](zeyi.lin@swanhub.co)ï¼šåé¦ˆå…³äºä½¿ç”¨SwanLabçš„é—®é¢˜
- <a href="https://geektechstudio.feishu.cn/wiki/NIZ9wp5LRiSqQykizbGcVzUKnic">å¾®ä¿¡äº¤æµç¾¤</a>ï¼šäº¤æµä½¿ç”¨SwanLabçš„é—®é¢˜ã€åˆ†äº«æœ€æ–°çš„AIæŠ€æœ¯

### SwanLab READMEå¾½ç« 

å¦‚æœä½ å–œæ¬¢åœ¨å·¥ä½œä¸­ä½¿ç”¨ SwanLabï¼Œè¯·å°† SwanLab å¾½ç« æ·»åŠ åˆ°ä½ çš„READMEä¸­ï¼š

[![swanlab](https://img.shields.io/badge/powered%20by-SwanLab-438440)](https://github.com/swanhubx/swanlab)

```
[![swanlab](https://img.shields.io/badge/powered%20by-SwanLab-438440)](https://github.com/swanhubx/swanlab)
```

### åœ¨è®ºæ–‡ä¸­å¼•ç”¨SwanLab

å¦‚æœæ‚¨å‘ç° SwanLab å¯¹æ‚¨çš„ç ”ç©¶ä¹‹æ—…æœ‰å¸®åŠ©ï¼Œè¯·è€ƒè™‘ä»¥ä¸‹åˆ—æ ¼å¼å¼•ç”¨ï¼š

```bibtex
@software{Zeyilin_SwanLab_2023,
  author = {Zeyi Lin, Shaohong Chen, Kang Li, Qiushan Jiang, Zirui Cai,  Kaifang Ji and {The SwanLab team}},
  license = {Apache-2.0},
  title = {{SwanLab}},
  url = {https://github.com/swanhubx/swanlab},
  year = {2023}
}
```

### ä¸ºSwanLabåšå‡ºè´¡çŒ®

è€ƒè™‘ä¸ºSwanLabåšå‡ºè´¡çŒ®å—ï¼Ÿé¦–å…ˆï¼Œè¯·èŠ±ç‚¹æ—¶é—´é˜…è¯» [è´¡çŒ®æŒ‡å—](CONTRIBUTING.md)ã€‚

åŒæ—¶ï¼Œæˆ‘ä»¬éå¸¸æ¬¢è¿é€šè¿‡ç¤¾äº¤åª’ä½“ã€æ´»åŠ¨å’Œä¼šè®®çš„åˆ†äº«æ¥æ”¯æŒSwanLabï¼Œè¡·å¿ƒæ„Ÿè°¢ï¼

### ä¸‹è½½Icon

[SwanLab-Icon-SVG](readme_files/swanlab-logo.svg)

<br>

**Contributors**

<a href="https://github.com/swanhubx/swanlab/graphs/contributors">
  <img src="https://contrib.rocks/image?repo=swanhubx/swanlab" />
</a>

<br>

## ğŸ“ƒ åè®®

æœ¬ä»“åº“éµå¾ª [Apache 2.0 License](https://github.com/SwanHubX/SwanLab/blob/main/LICENSE) å¼€æºåè®®
